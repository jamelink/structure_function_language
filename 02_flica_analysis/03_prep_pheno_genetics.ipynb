{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec5718e-9ed5-473f-85e5-37cb7c4e368b",
   "metadata": {},
   "source": [
    "## Prep data for exome analysis + GWAS\n",
    "Input:\n",
    "- preprocessed PLINK genome data\n",
    "- uncorrected brain data (edges, nodes and asymmetries from edges)\n",
    "\n",
    "Pipeline:\n",
    "- Concatenate nodes to one dataframe\n",
    "- Format df to match regenie\n",
    "- Regenie step 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f24ce65-daba-48c5-a48e-2cb47e091dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from numpy import savetxt, ceil\n",
    "\n",
    "base_path = \"/data/clusterfs/lag/users/jitame/SENT_CORE/\" \n",
    "\n",
    "#get csv file_names \n",
    "\n",
    "file_exts = [\"sent_edges_asym_N29682.csv\",  \"sent_edges_N29682.csv\"]\n",
    "file_names = [os.path.join(base_path, \"pheno\", x )  for x in file_exts]\n",
    "\n",
    "#read final exome subject list\n",
    "exome_sub_list = os.path.join(base_path, \"subj_sent_N30652_exome_final_pass_sex.txt\")\n",
    "exome_subs = [int(x) for x in open( exome_sub_list ).read().split('\\n')[:-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae4ffc4-4298-481e-b1d2-112c68ea37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = True\n",
    "unconcat = False\n",
    "\n",
    "def concat_dfs(fn, df):\n",
    "    \"\"\"\n",
    "    Concatenates two dataframes, one new, one existing.\n",
    "    Adds name of the phenotype to column names to new dataframe\n",
    "    \"\"\"\n",
    "    #get phenotype name\n",
    "    name_df = os.path.split(fn)[1].split('_')[0] + '_' + os.path.split(fn)[1].split('_')[1]\n",
    "    \n",
    "    #read df\n",
    "    df2 = pd.read_csv(fn, index_col=0)\n",
    "    \n",
    "    #set columns\n",
    "    df2.columns = [name_df + '_' + cn for cn in df2.columns]\n",
    "    \n",
    "    #concatenate dfs\n",
    "    df_new = pd.concat([df, df2], axis=1)\n",
    "    \n",
    "    #return df\n",
    "    return df_new\n",
    "\n",
    "\n",
    "def format_df_regenie(df, exome_subs=None):\n",
    "    \"\"\"\n",
    "    Formats input df to regenie format\n",
    "    \"\"\"   \n",
    "    #get subjects in exome data\n",
    "    if exome_subs is not None:\n",
    "        df = df.loc[exome_subs]\n",
    "    \n",
    "    #get NaN subs and remove them\n",
    "    nan_subs = list(df[df.isna().any(axis=1)].index.values)\n",
    "    df = df.drop(nan_subs)\n",
    "    \n",
    "    #get column names\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    if \"aicha_nodes_Unnamed: 0.1\" in cols:\n",
    "        cols.remove(\"aicha_nodes_Unnamed: 0.1\")\n",
    "    \n",
    "    #make index column a normal column\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    #set subject IDs\n",
    "    df[['FID']], df[['IID']] = df[[df.columns[0]]], df[[df.columns[0]]]\n",
    "    \n",
    "    #reorder\n",
    "    df = df[['FID', 'IID'] + cols]\n",
    "    return df\n",
    "\n",
    "def save_in_chunks(df, no_chunks, fn):\n",
    "    \"\"\"\n",
    "    Save dataframe in chunks\n",
    "    \"\"\"\n",
    "    #get column list\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    #specify ID vars and remove from other columns\n",
    "    ids = ['FID', 'IID']\n",
    "    for i in ids:\n",
    "        cols.remove(i)\n",
    "    \n",
    "    #calculate column chunk size\n",
    "    chunk_size = int(ceil(len(cols)/no_chunks))\n",
    "    \n",
    "    #chunk col list\n",
    "    chunked_list = [cols[j:j+chunk_size] for j in range(0, len(cols), chunk_size)]\n",
    "    \n",
    "    for j in range(no_chunks):\n",
    "        #get which columns to write in this chunk\n",
    "        cols_out = chunked_list[j]\n",
    "        \n",
    "        #write to memory\n",
    "        df.to_csv(fn[:-16]+\"exome_{0}_of_{1}.tsv.gz\".format(j, no_chunks),\n",
    "                  chunksize=1000, #sets row chunksize to write\n",
    "                  columns = cols_out,\n",
    "                  index = False,\n",
    "                  sep = \"\\t\",\n",
    "                  compression = \"gzip\")\n",
    "    \n",
    "if concat:\n",
    "    print(\"Process concatenate dfs\")\n",
    "    #specify empty dataframe to start\n",
    "    df=pd.DataFrame()\n",
    "\n",
    "    #read dataframes\n",
    "    for fn in file_names:\n",
    "        df = concat_dfs(fn, df)\n",
    "\n",
    "    #get subject list if necessary    \n",
    "    #nan_subs = list(df[df.isna().any(axis=1)].index.values)\n",
    "    #savetxt(os.path.join(base_path, 'nan_subs_sent_vs_aicha.txt'), nan_subs, delimiter=\"\\n\", fmt=\"%s\")\n",
    "\n",
    "    #reformat \n",
    "    df = format_df_regenie(df, exome_subs=exome_subs)\n",
    "\n",
    "    print(df.columns)\n",
    "\n",
    "    #save and then delete from memory to save space\n",
    "    df.to_csv(os.path.join(base_path, \"pheno\", \"sent_edges_exome.tsv\"), index=False, sep=\"\\t\")\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b664659-184b-490f-9b68-282483dccb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#read dataframe\n",
    "\n",
    "def make_covars_regenie_ready(fn_in, fn_out, exome_subs, exome=False):    \n",
    "    covars = pd.read_csv(fn_in, sep=\"\\t\", index_col=0)\n",
    "\n",
    "    #exome_subs.remove(5734558)\n",
    "    #select exome subs\n",
    "    covars = covars.loc[exome_subs]\n",
    "    \n",
    "    if exome:\n",
    "        exome_batch = pd.read_csv(\"/data/workspaces/lag/workspaces/lg-ukbiobank/derived_data/genetic_data/exome/exome_release_final/exome_batch/exome_batches.txt\", sep=\"\\t\", index_col=0)\n",
    "        covars[\"exome_batch\"] = exome_batch.loc[exome_subs]\n",
    "    \n",
    "    #get column order right\n",
    "    cols = list(covars.columns)\n",
    "    covars.reset_index(inplace=True)\n",
    "    print(covars.head())\n",
    "    \n",
    "    covars[['FID']], covars[['IID']] = covars[['subject_id']], covars[['subject_id']]\n",
    "    covars = covars[['FID', 'IID'] + cols]\n",
    "                           \n",
    "    #save to compressed file\n",
    "    covars.to_csv(fn_out, index=False, sep=\"\\t\")\n",
    "    \n",
    "in_files = [os.path.join(base_path, \"covars\", \"covars_pc10_for_correction_N30660_gwas_batch.txt\"), os.path.join(base_path, \"covars\", \"covars_pc10_for_correction_N30660_exome_gwas_batch.txt\")]\n",
    "out_files = [os.path.join(base_path, \"covars\", \"covars_pc10_gwas.tsv\"), os.path.join(base_path, \"covars\", \"covars_pc10_exome.tsv\")]\n",
    "\n",
    "make_covars_regenie_ready(in_files[0], out_files[0], exome_subs, exome=False)\n",
    "make_covars_regenie_ready(in_files[1], out_files[1], exome_subs, exome=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7760d105-d31d-45d5-bde2-146920336e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sex from covariates to FAM files\n",
    "def sex_to_fam(fam_file, covars):\n",
    "    \"\"\"\n",
    "    Loads sex from the covariates and adds it to the .FAM file\n",
    "    \"\"\"\n",
    "    #load fam file\n",
    "    fam = pd.read_csv(fam_file, sep=\"\\t\", header=None)\n",
    "    \n",
    "    #set order of covars identical to FAM-file\n",
    "    covars = covars.reindex(list(fam.iloc[:, 0]))\n",
    "    \n",
    "    #set fam file to sex\n",
    "    fam.iloc[:, 4] = [x+2 if x == 0 else x for x in covars['sex']]\n",
    "    \n",
    "    #save\n",
    "    fam.to_csv(fam_file, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "#Load covars\n",
    "covars = pd.read_csv(os.path.join(base_path, \"covars\", \"covars_pc10_for_correction_N30660.txt\"), sep=\"\\t\", index_col=0)\n",
    "\n",
    "#Specify chromosome\n",
    "chrs= [x for x in range(1, 23, 1)] + ['X']\n",
    "\n",
    "for i in chrs:\n",
    "    print(\"Chromosome {}\".format(i))\n",
    "    sex_to_fam(os.path.join(base_path, \"geno\", \"geno_N30652_chr{}.fam\".format(i)), covars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80c2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change path in predictions list\n",
    "import pandas as pd\n",
    "from os import rename\n",
    "\n",
    "#rename file\n",
    "pred_list = \"/data/clusterfs/lag/users/jitame/SENT_CORE/geno/regenie/step_1_sent_all/st1_out/reg_st1_sent_pred.list\"\n",
    "pred_list_old = \"/data/clusterfs/lag/users/jitame/SENT_CORE/geno/regenie/step_1_sent_all/st1_out/reg_st1_sent_pred_mpi_local.list\"\n",
    "rename(pred_list, pred_list_old)\n",
    "\n",
    "#edit path file\n",
    "df = pd.read_csv(pred_list_old, delimiter=\" \", header=None)\n",
    "df.iloc[:,1] = [x.replace(\"/data/clusterfs/lag/users/jitame/SENT_CORE/geno/regenie/step_1_sent_all/st1_out/\", \"/input_files/\") for x in df.iloc[:,1]]\n",
    "df.to_csv(pred_list, header=False, index=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00843f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#GZIP predictions\n",
    "pred_path=/data/clusterfs/lag/users/jitame/SENT_CORE/geno/regenie/step_1_sent_all/st1_out\n",
    "out_file=/data/clusterfs/lag/users/jitame/SENT_CORE/geno/regenie/step_1_sent_all.tar.gz\n",
    "cd $pred_path\n",
    "tar cfz $out_file *.loco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
